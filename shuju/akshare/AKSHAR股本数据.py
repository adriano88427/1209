import sys
import subprocess
import time
import os
import threading
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
import pandas as pd

# æŸ¥è¯¢å¼€å…³ï¼šå°†å¯¹åº”å€¼æ”¹ä¸º False å¯è·³è¿‡è¯¥æ¨¡å—çš„æ‰€æœ‰è¯·æ±‚
def _flag(value: str) -> bool:
    return value in {"æ˜¯", "true", "True", "1", True}


FEATURE_FLAGS = {
    "è·å–ä»·æ ¼": _flag("æ˜¯"),
    "è·å–æµé€šè‚¡æœ¬": _flag("æ˜¯"),
    "è·å–é«˜ç®¡å˜åŠ¨": _flag("å¦"),
    "è·å–ä¸€è‡´è¡ŒåŠ¨äºº": _flag("å¦"),
    "è·å–ä¸Šå¸‚ä¿¡æ¯": _flag("å¦"),
    "è·å–å†å²åå¤§è‚¡ä¸œ": _flag("å¦"),
    "è·å–åå¤§æµé€šè‚¡ä¸œ": _flag("å¦"),
    "è·å–æœºæ„æŒä»“": _flag("å¦"),
}

# è‡ªåŠ¨å®šä½è‚¡ç¥¨æ•°æ®æ–‡ä»¶ï¼ˆé»˜è®¤ä½¿ç”¨åŒç›®å½•ä¸‹çš„æ•°æ®ï¼‰
script_dir = os.path.dirname(os.path.abspath(__file__))
DEFAULT_STOCK_DATA_FILE = "è‚¡ç¥¨åˆ—è¡¨.xlsx"
excel2_path = os.path.join(script_dir, DEFAULT_STOCK_DATA_FILE)

if not os.path.exists(excel2_path):
    print(f"è‚¡ç¥¨æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {excel2_path}")
    sys.exit(1)

try:
    df_stocks = pd.read_excel(excel2_path, sheet_name='Sheet1')
except Exception as e:
    print(f"âŒâŒâŒâŒ è¯»å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {str(e)}")
    sys.exit(1)

if 'ä¿¡å·æ—¥æœŸ' not in df_stocks.columns:
    print("âŒâŒâŒâŒ è‚¡ç¥¨æ•°æ®æ–‡ä»¶ç¼ºå°‘â€œä¿¡å·æ—¥æœŸâ€åˆ—ï¼Œæ— æ³•æ¨å¯¼ç›®æ ‡æ—¥æœŸ")
    sys.exit(1)

signal_dates = pd.to_datetime(df_stocks['ä¿¡å·æ—¥æœŸ'], errors='coerce').dropna()
if signal_dates.empty:
    print("âŒâŒâŒâŒ â€œä¿¡å·æ—¥æœŸâ€åˆ—æ²¡æœ‰å¯ç”¨æ—¥æœŸï¼Œæ— æ³•æ¨å¯¼ç›®æ ‡æ—¥æœŸ")
    sys.exit(1)

reference_signal_date = signal_dates.max()
target_year = reference_signal_date.year - 1
if target_year < 1900:
    print("âŒâŒâŒâŒ æ¨å¯¼å‡ºçš„ç›®æ ‡å¹´ä»½æ— æ•ˆ")
    sys.exit(1)

target_date = f"{target_year}1231"
system_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
save_path = os.path.join(script_dir, f"è‚¡ç¥¨ç»¼åˆåˆ†æ_{system_timestamp}.xlsx")

print(f"è‚¡ç¥¨æ•°æ®æ–‡ä»¶: {excel2_path}")
print(f"å‚è€ƒä¿¡å·æ—¥æœŸ: {reference_signal_date.strftime('%Y-%m-%d')}")
print(f"ç›®æ ‡æ—¥æœŸ: {target_date} (ä¿¡å·æ—¥æœŸå‰ä¸€å¹´æœ«)")
print(f"ç»“æœæ–‡ä»¶: {save_path}")

try:
    import akshare as ak
    print("akshare å·²æˆåŠŸå¯¼å…¥")
except ImportError:
    print("æœªæ‰¾åˆ° akshare æ¨¡å—ï¼Œæ­£åœ¨å®‰è£…...")
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "akshare"])
        import akshare as ak
        print("akshare å®‰è£…æˆåŠŸå¹¶å¯¼å…¥")
    except Exception as e:
        print(f"å®‰è£… akshare å¤±è´¥: {str(e)}")
        sys.exit(1)

from akshare_client import AkShareClient
from akshare_config import DEFAULT_CLIENT_CONFIG

client_config = DEFAULT_CLIENT_CONFIG
client = AkShareClient(client_config)
stock_info_dict_cache = {}
stock_info_lock = threading.Lock()
price_main_disabled = False
CNINFO_SHARE_START_DATE = "19900101"
cninfo_share_cache = {}
cninfo_share_failures = set()
cninfo_share_lock = threading.Lock()


def get_stock_info_dict(stock_code: str):
    stock_code = str(stock_code).zfill(6)
    with stock_info_lock:
        cached = stock_info_dict_cache.get(stock_code)
    if cached is not None:
        return cached
    info_value = {}
    try:
        info_df = client.stock_individual_info(stock_code)
        if isinstance(info_df, pd.DataFrame) and not info_df.empty:
            info_value = dict(zip(info_df["item"], info_df["value"]))
    except Exception as exc:
        print(f"âš ï¸ è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {stock_code} - {exc}")
    with stock_info_lock:
        stock_info_dict_cache[stock_code] = info_value
    return info_value


def prefetch_stock_info(codes):
    unique_codes = list({str(code).zfill(6) for code in codes})
    if not unique_codes:
        return
    print(f"ğŸ§µ æ­£åœ¨å¹¶è¡Œé¢„çƒ­ {len(unique_codes)} åªè‚¡ç¥¨çš„åŸºç¡€ä¿¡æ¯...")

    def worker(code: str):
        get_stock_info_dict(code)

    max_workers = min(8, len(unique_codes))
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(worker, code) for code in unique_codes]
        for future in as_completed(futures):
            future.result()


def ensure_cninfo_share_data(stock_code: str):
    stock_code = str(stock_code).zfill(6)
    with cninfo_share_lock:
        cached = cninfo_share_cache.get(stock_code)
    if cached is not None:
        return cached
    with cninfo_share_lock:
        if stock_code in cninfo_share_failures:
            return None
    start_date = CNINFO_SHARE_START_DATE
    end_date = datetime.now().strftime("%Y%m%d")
    try:
        print(f"  â³ è·å–CNInfoè‚¡æœ¬æ•°æ®: {stock_code} ({start_date}-{end_date})")
        df = client.stock_share_change(stock_code, start_date, end_date)
    except Exception as exc:
        print(f"âš ï¸ CNInfoè‚¡æœ¬æ•°æ®è¯·æ±‚å¤±è´¥ ({stock_code}): {exc}")
        with cninfo_share_lock:
            cninfo_share_failures.add(stock_code)
        return None
    if not isinstance(df, pd.DataFrame) or df.empty:
        print(f"âš ï¸ CNInfoè‚¡æœ¬æ•°æ®ä¸ºç©º ({stock_code})")
        with cninfo_share_lock:
            cninfo_share_failures.add(stock_code)
        return None
    df = df.copy()
    df["å˜åŠ¨æ—¥æœŸ"] = pd.to_datetime(df.get("å˜åŠ¨æ—¥æœŸ"), errors="coerce")
    df["å·²æµé€šè‚¡ä»½"] = pd.to_numeric(df.get("å·²æµé€šè‚¡ä»½"), errors="coerce")
    df.sort_values("å˜åŠ¨æ—¥æœŸ", inplace=True)
    with cninfo_share_lock:
        cninfo_share_cache[stock_code] = df
    print(f"âœ… CNInfoè‚¡æœ¬æ•°æ®ç¼“å­˜å®Œæˆ: {stock_code} å…± {len(df)} æ¡è®°å½•")
    return df


def get_cninfo_circulating_shares(stock_code: str, reference_date: str):
    df = ensure_cninfo_share_data(stock_code)
    if df is None or df.empty:
        return None
    try:
        ref_datetime = pd.to_datetime(reference_date, errors="coerce")
    except Exception:
        ref_datetime = None
    if pd.isna(ref_datetime):
        print(f"âš ï¸ æ— æ³•è§£æå‚è€ƒæ—¥æœŸ {reference_date}ï¼Œè·³è¿‡CNInfoå†å²åŒ¹é…")
        return None
    df_valid = df.dropna(subset=["å·²æµé€šè‚¡ä»½"])
    if df_valid.empty:
        print(f"âš ï¸ CNInfoè®°å½•ç¼ºå°‘å·²æµé€šè‚¡ä»½å­—æ®µ ({stock_code})")
        return None
    df_with_dates = df_valid[df_valid["å˜åŠ¨æ—¥æœŸ"].notna()]
    df_before = df_with_dates[df_with_dates["å˜åŠ¨æ—¥æœŸ"] <= ref_datetime]
    if not df_before.empty:
        row = df_before.iloc[-1]
        out_of_range = False
    else:
        if df_with_dates.empty:
            print(f"âš ï¸ CNInfoè®°å½•ç¼ºå°‘æœ‰æ•ˆå˜åŠ¨æ—¥æœŸ ({stock_code})")
            return None
        row = df_with_dates.iloc[0]
        out_of_range = True
        print(f"âš ï¸ ä¿¡å·æ—¥ {reference_date} æ—©äºCNInfoé¦–æ¡è®°å½• ({stock_code})ï¼Œä½¿ç”¨æœ€æ—©ä¸€æ¬¡å˜åŠ¨æ•°æ® {row['å˜åŠ¨æ—¥æœŸ'].date()}")
    shares = row["å·²æµé€šè‚¡ä»½"]
    if pd.isna(shares):
        return None
    # CNInfo è¿”å›å•ä½ä¸ºâ€œä¸‡è‚¡â€ï¼Œæ¢ç®—æˆè‚¡
    shares = float(shares) * 10000
    change_date = row["å˜åŠ¨æ—¥æœŸ"]
    change_date_str = change_date.strftime("%Y%m%d") if pd.notna(change_date) else ""
    if out_of_range:
        print(f"   â®• CNInfoæœ€è¿‘ä¸€æ¬¡å˜åŠ¨æ—¥æœŸ: {change_date_str}")
    return float(shares), change_date_str


def get_circulating_shares_from_stock_info(stock_code: str):
    info_dict = get_stock_info_dict(stock_code)
    for key, value in info_dict.items():
        if "æµé€šè‚¡" in str(key):
            value_str = str(value).replace(",", "")
            try:
                if "äº¿" in value_str:
                    return float(value_str.replace("äº¿", "")) * 100000000
                return float(value_str)
            except ValueError:
                continue
    return None


def get_circulating_shares(stock_code: str, reference_date: str):
    if not FEATURE_FLAGS["è·å–æµé€šè‚¡æœ¬"]:
        return None
    cninfo_result = get_cninfo_circulating_shares(stock_code, reference_date)
    if cninfo_result:
        shares, change_date_str = cninfo_result
        return shares, change_date_str, "CNInfo"
    fallback = get_circulating_shares_from_stock_info(stock_code)
    if fallback is not None:
        return fallback, "", "ä¸œæ–¹è´¢å¯Œ"
    return None


def build_shared_maps(target_dates, hold_types):
    yzxdr_map = {}
    if FEATURE_FLAGS["è·å–ä¸€è‡´è¡ŒåŠ¨äºº"]:
        for target_date in target_dates:
            temp_map = defaultdict(set)
            try:
                yzxdr_df = client.stock_yzxdr(target_date)
                if isinstance(yzxdr_df, pd.DataFrame) and not yzxdr_df.empty:
                    for _, row in yzxdr_df.iterrows():
                        code = row.get("è‚¡ç¥¨ä»£ç ")
                        names = row.get("ä¸€è‡´è¡ŒåŠ¨äºº")
                        if code and isinstance(names, str):
                            for name in names.split(","):
                                cleaned = name.strip()
                                if cleaned:
                                    temp_map[code].add(cleaned)
            except Exception as exc:
                print(f"âš ï¸ é¢„è·å–ä¸€è‡´è¡ŒåŠ¨äººå¤±è´¥ (æ—¥æœŸ: {target_date}): {exc}")
            yzxdr_map[target_date] = temp_map
    else:
        for target_date in target_dates:
            yzxdr_map[target_date] = defaultdict(set)

    fund_hold_map = {}
    if FEATURE_FLAGS["è·å–æœºæ„æŒä»“"]:
        for target_date in target_dates:
            fund_hold_map[target_date] = {}
            for hold_type in hold_types:
                fund_hold_map[target_date][hold_type] = {}
                try:
                    df_hold = client.stock_report_fund_hold(hold_type, target_date)
                    if (
                        isinstance(df_hold, pd.DataFrame)
                        and not df_hold.empty
                        and "è‚¡ç¥¨ä»£ç " in df_hold.columns
                    ):
                        for _, row in df_hold.iterrows():
                            code = str(row.get("è‚¡ç¥¨ä»£ç ", "")).strip().zfill(6)
                            if code:
                                fund_hold_map[target_date][hold_type][code] = row
                except Exception as exc:
                    print(f"âš ï¸ é¢„è·å– {hold_type} æ•°æ®å¤±è´¥ (æ—¥æœŸ: {target_date}): {exc}")
    else:
        for target_date in target_dates:
            fund_hold_map[target_date] = {hold: {} for hold in hold_types}
    return yzxdr_map, fund_hold_map

def fetch_price_from_backup(stock_code_str: str, price_date: str):
    """ä½¿ç”¨å¤‡ç”¨æ¥å£ï¼ˆæ–°æµªï¼‰è·å–æŒ‡å®šæ—¥æœŸçš„æ”¶ç›˜ä»·"""
    try:
        prefix = "sh" if stock_code_str.startswith("6") else "sz"
        df = ak.stock_zh_a_daily(symbol=f"{prefix}{stock_code_str}")
        if df.empty or "date" not in df.columns or "close" not in df.columns:
            return None
        df["date"] = pd.to_datetime(df["date"])
        target_datetime = pd.to_datetime(price_date)
        available = df[df["date"] <= target_datetime]
        if available.empty:
            return None
        row = available.iloc[-1]
        return float(row["close"]), row["date"]
    except Exception as exc:
        print(f"âš ï¸ å¤‡ç”¨ä»·æ ¼æ¥å£å¤±è´¥ ({stock_code_str}): {exc}")
        return None


def get_circ_mv_on_date(stock_code, price_date):
    """è·å–æŒ‡å®šè‚¡ç¥¨åœ¨ä¿¡å·å½“æ—¥ï¼ˆæˆ–è¯¥æ—¥æœ€è¿‘äº¤æ˜“æ—¥ï¼‰æ”¶ç›˜ä»·å¯¹åº”çš„æµé€šå¸‚å€¼"""
    stock_code_str = str(stock_code).zfill(6)

    closing_price = None
    used_date = None

    global price_main_disabled

    main_price_available = FEATURE_FLAGS["è·å–ä»·æ ¼"] and not price_main_disabled

    fallback_due_to_connection = False

    try:
        if main_price_available:
            start_date = price_date[:6] + "01"
            hist_data = client.stock_hist(symbol=stock_code_str, start_date=start_date, end_date=price_date)

            if hist_data.empty:
                raise ValueError("ä¸»è¡Œæƒ…æ¥å£æ— æ•°æ®")

            hist_data['æ—¥æœŸ'] = pd.to_datetime(hist_data['æ—¥æœŸ'])
            hist_data.set_index('æ—¥æœŸ', inplace=True)

            target_datetime = pd.to_datetime(price_date)
            if target_datetime not in hist_data.index:
                print(f"âš ï¸ åœ¨å†å²æ•°æ®ä¸­æœªæ‰¾åˆ°æ—¥æœŸ {price_date} çš„è®°å½•ï¼Œå°è¯•è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥æ•°æ® (è‚¡ç¥¨: {stock_code_str})")
                prev_trading_day = hist_data.index[hist_data.index < target_datetime].max()
                closing_price = hist_data.loc[prev_trading_day]['æ”¶ç›˜']
                used_date = prev_trading_day
                print(f"âœ… ä½¿ç”¨å‰ä¸€ä¸ªäº¤æ˜“æ—¥ {prev_trading_day.strftime('%Y%m%d')} çš„æ”¶ç›˜ä»·: {closing_price:.2f} å…ƒ")
            else:
                closing_price = hist_data.loc[target_datetime]['æ”¶ç›˜']
                used_date = target_datetime
                print(f"âœ… è·å–æ”¶ç›˜ä»·æˆåŠŸ: {stock_code_str} åœ¨ {price_date} çš„æ”¶ç›˜ä»·ä¸º {closing_price:.2f} å…ƒ")
        else:
            raise RuntimeError("ä¸»è¡Œæƒ…æ¥å£å·²ç¦ç”¨")

    except Exception as e:
        if "RemoteDisconnected" in str(e) or "Connection aborted" in str(e):
            price_main_disabled = True
            print("ğŸ›‘ æ£€æµ‹åˆ°ä¸œæ–¹è´¢å¯Œè¡Œæƒ…æ¥å£è¢«å°ï¼Œåç»­å°†ç›´æ¥ä½¿ç”¨å¤‡ç”¨æ¥å£ã€‚")
            fallback_due_to_connection = True
        else:
            print(f"âš ï¸ ä¸»è¡Œæƒ…æ¥å£å¤±è´¥ (è‚¡ç¥¨: {stock_code_str}): {str(e)}ï¼Œå°è¯•å¤‡ç”¨æ¥å£")
        backup = fetch_price_from_backup(stock_code_str, price_date)
        if backup is None:
            print(f"âš ï¸ å¤‡ç”¨æ¥å£ä¹Ÿæ— æ³•è·å–ä»·æ ¼ (è‚¡ç¥¨: {stock_code_str})")
            return None
        closing_price, backup_date = backup
        used_date = pd.to_datetime(price_date) if fallback_due_to_connection else backup_date
        backup_msg_date = backup_date.strftime('%Y%m%d')
        print(f"âœ… å¤‡ç”¨æ¥å£è·å–æ”¶ç›˜ä»·æˆåŠŸ: {stock_code_str} åœ¨ {backup_msg_date} çš„æ”¶ç›˜ä»·ä¸º {closing_price:.2f} å…ƒ")
        if fallback_due_to_connection and backup_msg_date != price_date:
            print(f"   â®• ä¸ºä¿æŒä¿¡å·æ—¥æœŸä¸€è‡´ï¼Œç»“æœä¸­ä»ä½¿ç”¨ä¿¡å·æ—¥ {price_date}")

    circ_info = get_circulating_shares(stock_code_str, price_date)
    if circ_info is None:
        print(f"âš ï¸ æœªæ‰¾åˆ°æµé€šè‚¡æœ¬æ•°æ® (è‚¡ç¥¨: {stock_code_str})")
        return None

    circ_shares, share_date_str, share_source = circ_info
    if share_source == "CNInfo":
        date_display = share_date_str or "æœªçŸ¥æ—¥æœŸ"
        print(f"âœ… CNInfoæµé€šè‚¡æœ¬åŒ¹é…æˆåŠŸ: {stock_code_str} åœ¨ {date_display} çš„æµé€šè‚¡æœ¬ä¸º {circ_shares:,.0f} è‚¡")
    else:
        print(f"âœ… è·å–æµé€šè‚¡æœ¬æˆåŠŸ(ä¸œæ–¹è´¢å¯Œ): {stock_code_str} çš„æµé€šè‚¡æœ¬ä¸º {circ_shares:,.0f} è‚¡")
    circulating_mv = circ_shares * closing_price
    used_date_str = used_date.strftime("%Y%m%d")
    print(f"âœ… è®¡ç®—æµé€šå¸‚å€¼æˆåŠŸ: {stock_code_str} åœ¨ {used_date_str} çš„æµé€šå¸‚å€¼ä¸º {circulating_mv:,.2f} å…ƒ")
    return circulating_mv, closing_price, used_date_str

# ä»EXCELè¯»å–è‚¡ç¥¨æ•°æ®
try:
    print(f"âœ… æˆåŠŸè¯»å–è‚¡ç¥¨åˆ—è¡¨: å…± {len(df_stocks)} åªè‚¡ç¥¨")
    
    stock_entries = []
    for _, row in df_stocks.iterrows():
        name = str(row['è‚¡ç¥¨åç§°']).strip()
        code = str(row['è‚¡ç¥¨ä»£ç ']).strip().zfill(6)
        code_with_prefix = f"sz{code}" if code.startswith('0') or code.startswith('3') else f"sh{code}"
        signal_date_val = row.get('ä¿¡å·æ—¥æœŸ')
        signal_dt = pd.to_datetime(signal_date_val, errors='coerce')
        if pd.isna(signal_dt):
            continue
        target_year_for_stock = signal_dt.year - 1
        if target_year_for_stock < 1900:
            entry_target_date = target_date
        else:
            entry_target_date = f"{target_year_for_stock}1231"
        stock_entries.append({
            "name": name,
            "code": code,
            "code_with_prefix": code_with_prefix,
            "signal_date": signal_dt.strftime("%Y%m%d"),
            "target_date": entry_target_date,
        })

    if not stock_entries:
        print("âŒâŒâŒâŒ è¾“å…¥è¡¨å†…æ— æœ‰æ•ˆä¿¡å·è®°å½•")
        sys.exit(1)

    sample_names = [entry['name'] for entry in stock_entries[:3]]
    print(f"âœ… å·²åŠ è½½è‚¡ç¥¨åˆ—è¡¨: {sample_names}...ç­‰ {len(stock_entries)} æ¡è®°å½•")

    if client_config.enable_async_prefetch:
        prefetch_stock_info([entry["code"] for entry in stock_entries])
    
except Exception as e:
    print(f"âŒâŒâŒâŒ å¤„ç†è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {str(e)}")
    sys.exit(1)

categories = ["å…¶å®ƒ", "æŠ•èµ„å…¬å¸", "ç§å‹ŸåŸºé‡‘", "é›†åˆç†è´¢è®¡åˆ’", "å…¶ä»–ç†è´¢äº§å“", "å‘˜å·¥æŒè‚¡è®¡åˆ’"]
hold_types = ["ä¿¡æ‰˜æŒä»“", "ç¤¾ä¿æŒä»“", "QFIIæŒä»“", "ä¿é™©æŒä»“", "åŸºé‡‘æŒä»“", "åˆ¸å•†æŒä»“"]

default_target_date = target_date
target_dates_for_fetch = sorted({entry["target_date"] for entry in stock_entries} | {default_target_date})

result_list = []
cache = {}
start_time = datetime.now()
total_stocks = len(stock_entries)
print(f"â±â±â±â±â±â±â±â±â±ï¸ å¼€å§‹æ‰§è¡Œæ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
print(f"ğŸ“ŠğŸ“ŠğŸ“ŠğŸ“Š å…±éœ€å¤„ç† {total_stocks} æ¡è‚¡ç¥¨-ä¿¡å·è®°å½•")

print("ğŸ”„ æ­£åœ¨é¢„è·å–å…±äº«æ•°æ®...")
shared_yzxdr_map, fund_hold_map = build_shared_maps(target_dates_for_fetch, hold_types)
print("âœ… å…±äº«æ•°æ®é¢„è·å–å®Œæˆ")

processed_keys = set()
if os.path.exists(save_path):
    try:
        existing_df = pd.read_excel(save_path)
        if 'æ•°æ®æ—¥æœŸ' in existing_df.columns:
            names = existing_df['è‚¡ç¥¨åç§°'].astype(str)
            dates = existing_df['æ•°æ®æ—¥æœŸ'].astype(str).fillna(default_target_date)
            if 'åŸå§‹ä¿¡å·æ—¥æœŸ' in existing_df.columns:
                signal_series = existing_df['åŸå§‹ä¿¡å·æ—¥æœŸ'].astype(str).fillna("")
            elif 'ä¿¡å·å½“æ—¥æ—¥æœŸ' in existing_df.columns:
                signal_series = existing_df['ä¿¡å·å½“æ—¥æ—¥æœŸ'].astype(str).fillna("")
            else:
                signal_series = pd.Series([''] * len(existing_df))
            processed_keys = set(zip(names, dates, signal_series))
        else:
            processed_keys = {(str(name), default_target_date, "") for name in existing_df['è‚¡ç¥¨åç§°'].tolist()}
        print(f"âœ… å‘ç°å·²æœ‰ç»“æœæ–‡ä»¶ï¼Œå·²å¤„ç† {len(processed_keys)} æ¡è®°å½•")
    except Exception as e:
        print(f"âš ï¸ è¯»å–ç°æœ‰ç»“æœæ–‡ä»¶å¤±è´¥: {str(e)}")

stocks_to_process = [
    entry
    for entry in stock_entries
    if (entry["name"], entry["target_date"], entry["signal_date"]) not in processed_keys
]
print(f"ğŸ“ŠğŸ“ŠğŸ“ŠğŸ“Š éœ€è¦å¤„ç† {len(stocks_to_process)} æ¡æ–°è®°å½•")

for idx, entry in enumerate(stocks_to_process, 1):
    stock_name = entry["name"]
    stock_code_pure = entry["code"]
    stock_code_with_prefix = entry["code_with_prefix"]
    entry_signal_date = entry.get("signal_date")
    print(f"\nğŸ”ğŸ”ğŸ”ğŸ” [{idx}/{len(stocks_to_process)}] æ­£åœ¨å¤„ç†è‚¡ç¥¨: {stock_name}")
    
    cache_key = (stock_name, entry["target_date"], entry_signal_date)
    if cache_key in cache:
        cached_row = cache[cache_key].copy()
        if entry_signal_date:
            cached_row['åŸå§‹ä¿¡å·æ—¥æœŸ'] = entry_signal_date
        result_list.append(cached_row)
        print(f"âœ… ä½¿ç”¨ç¼“å­˜æ•°æ®: {stock_name} - {entry['target_date']} - {entry_signal_date}")
        continue

    current_target_date = entry.get("target_date") or default_target_date
    if current_target_date not in shared_yzxdr_map:
        current_target_date = default_target_date

    # è·å–æµé€šå¸‚å€¼
    price_date = entry_signal_date or current_target_date
    signal_price = None
    signal_price_date = None
    if FEATURE_FLAGS["è·å–ä»·æ ¼"]:
        price_info = get_circ_mv_on_date(stock_code_pure, price_date)
        if price_info is None:
            print(f"âš ï¸ æ— æ³•è·å–æµé€šå¸‚å€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼0 (è‚¡ç¥¨: {stock_name})")
            circulating_mv = 0
        else:
            circulating_mv, signal_price, signal_price_date = price_info
    else:
        print(f"âš ï¸ å·²å…³é—­æµé€šå¸‚å€¼æŸ¥è¯¢ï¼Œä½¿ç”¨é»˜è®¤å€¼0 (è‚¡ç¥¨: {stock_name})")
        circulating_mv = 0

    # é«˜ç®¡æŒè‚¡å˜åŠ¨æŸ¥è¯¢
    insider_names = set()
    if FEATURE_FLAGS["è·å–é«˜ç®¡å˜åŠ¨"]:
        try:
            print("  æ­£åœ¨æŸ¥è¯¢é«˜ç®¡æŒè‚¡å˜åŠ¨...")
            exec_df = client.stock_management_change(stock_code_with_prefix[2:])
            if isinstance(exec_df, pd.DataFrame) and not exec_df.empty:
                insider_names = set(exec_df["å˜åŠ¨äºº"].tolist())
                print(f"âœ… é«˜ç®¡æŒè‚¡å˜åŠ¨æ•°æ®æŸ¥è¯¢æˆåŠŸ: {stock_name}")
            else:
                print(f"âš ï¸ æœªæŸ¥è¯¢åˆ°é«˜ç®¡æŒè‚¡å˜åŠ¨æ•°æ®: {stock_name}")
        except Exception as e:
            print(f"âš ï¸ é«˜ç®¡æŒè‚¡å˜åŠ¨æŸ¥è¯¢å¤±è´¥ (è‚¡ç¥¨: {stock_name}): {str(e)}")
    else:
        print("âš ï¸ å·²å…³é—­é«˜ç®¡æŒè‚¡å˜åŠ¨æŸ¥è¯¢")

    # ä¸€è‡´è¡ŒåŠ¨äººæŸ¥è¯¢
    if FEATURE_FLAGS["è·å–ä¸€è‡´è¡ŒåŠ¨äºº"]:
        yzxdr_names = shared_yzxdr_map.get(current_target_date, {}).get(stock_code_with_prefix, set())
        if yzxdr_names:
            print(f"âœ… ä¸€è‡´è¡ŒåŠ¨äººæ•°æ®å‘½ä¸­ç¼“å­˜: {stock_name}")
            insider_names.update(yzxdr_names)
        else:
            print(f"âš ï¸ æœªæŸ¥è¯¢åˆ°ä¸€è‡´è¡ŒåŠ¨äººæ•°æ® (è‚¡ç¥¨: {stock_name})")
    else:
        yzxdr_names = set()
        print("âš ï¸ å·²å…³é—­ä¸€è‡´è¡ŒåŠ¨äººæŸ¥è¯¢")

    # è·å–ä¸Šå¸‚æ—¶é—´
    OLDDATE = "20191231"
    if FEATURE_FLAGS["è·å–ä¸Šå¸‚ä¿¡æ¯"]:
        try:
            print("  æ­£åœ¨è·å–ä¸Šå¸‚æ—¶é—´...")
            info_dict = get_stock_info_dict(stock_code_pure)
            list_date = str(info_dict.get("ä¸Šå¸‚æ—¶é—´", "")).strip()
            if list_date:
                try:
                    list_date_obj = datetime.strptime(list_date, "%Y-%m-%d")
                except ValueError:
                    try:
                        list_date_obj = datetime.strptime(list_date, "%Y%m%d")
                    except ValueError:
                        list_date_obj = None
                        print(f"âš ï¸ æ— æ³•è§£æä¸Šå¸‚æ—¶é—´æ ¼å¼: {list_date}ï¼Œä½¿ç”¨é»˜è®¤å€¼ {OLDDATE}")
                if list_date_obj:
                    query_date_obj = datetime.strptime(current_target_date, "%Y%m%d")
                    time_difference = (query_date_obj - list_date_obj).days / 365.25
                    OLDDATE = "20191231" if time_difference > 5 else f"{list_date_obj.year}1231"
                    print(f"âœ… è·å–ä¸Šå¸‚æ—¶é—´æˆåŠŸ: {stock_name} ä¸Šå¸‚äº {list_date}ï¼Œä½¿ç”¨å†å²æ—¥æœŸ {OLDDATE}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°ä¸Šå¸‚æ—¶é—´å­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼: {OLDDATE}")
        except Exception as e:
            print(f"âš ï¸ è·å–ä¸Šå¸‚æ—¶é—´å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å€¼: {OLDDATE}")
    else:
        print("âš ï¸ å·²å…³é—­ä¸Šå¸‚æ—¶é—´æŸ¥è¯¢ï¼Œä½¿ç”¨é»˜è®¤å†å²æ—¥æœŸ")

    # å†å²åå¤§è‚¡ä¸œæŸ¥è¯¢
    historical_insiders = set()
    if FEATURE_FLAGS["è·å–å†å²åå¤§è‚¡ä¸œ"]:
        try:
            print("  æ­£åœ¨æŸ¥è¯¢å†å²åå¤§è‚¡ä¸œ...")
            historical_df = client.stock_top10_history(stock_code_with_prefix, OLDDATE)
            if isinstance(historical_df, pd.DataFrame) and not historical_df.empty:
                historical_insiders = set(historical_df["è‚¡ä¸œåç§°"].tolist())
                print(f"âœ… å†å²åå¤§è‚¡ä¸œæŸ¥è¯¢æˆåŠŸ: {stock_name} (æ—¥æœŸ: {OLDDATE})")
            else:
                print(f"âš ï¸ æœªæŸ¥è¯¢åˆ°å†å²åå¤§è‚¡ä¸œæ•°æ® (è‚¡ç¥¨: {stock_name})")
        except Exception as e:
            print(f"âš ï¸ å†å²åå¤§è‚¡ä¸œæŸ¥è¯¢å¤±è´¥ (è‚¡ç¥¨: {stock_name}): {str(e)}")
    else:
        print("âš ï¸ å·²å…³é—­å†å²åå¤§è‚¡ä¸œæŸ¥è¯¢")

    # åå¤§æµé€šè‚¡ä¸œå¤„ç†
    category_ratios = {category: 0.0 for category in categories}
    hk_ratio = enterprise_ratio = insider_ratio = retail_ratio = 0.0
    small_non_ratio = small_non_enterprise_ratio = 0.0
    
    # ä»£ç 2ä¸­çš„æ–°å¢æŒ‡æ ‡
    top10_total_ratio = 0.0
    top10_small_non_ratio = 0.0
    top10_large_non_ratio = 0.0
    institutional_large_non_ratio = 0.0
    institutional_small_non_ratio = 0.0

    if FEATURE_FLAGS["è·å–åå¤§æµé€šè‚¡ä¸œ"]:
        try:
            print("  æ­£åœ¨æŸ¥è¯¢åå¤§æµé€šè‚¡ä¸œ...")
            df = client.stock_top10_free(stock_code_with_prefix, current_target_date)
            required_cols = {'è‚¡ä¸œåç§°', 'è‚¡ä¸œæ€§è´¨', 'å æ€»æµé€šè‚¡æœ¬æŒè‚¡æ¯”ä¾‹'}
            if df.empty:
                print(f"âš ï¸ æœªè·å–åˆ°åå¤§æµé€šè‚¡ä¸œæ•°æ® (è‚¡ç¥¨: {stock_name})")
            elif not required_cols.issubset(set(df.columns)):
                print(f"âš ï¸ åå¤§æµé€šè‚¡ä¸œæ•°æ®åˆ—ç¼ºå¤± (è‚¡ç¥¨: {stock_name})ï¼Œåˆ—: {list(df.columns)}")
            else:
                for _, row in df.iterrows():
                    holder_name = row['è‚¡ä¸œåç§°']
                    holder_type = row.get('è‚¡ä¸œæ€§è´¨', '')
                    holding_ratio = row['å æ€»æµé€šè‚¡æœ¬æŒè‚¡æ¯”ä¾‹']
                    
                    # ä»£ç 1åŸæœ‰é€»è¾‘
                    if holder_type == 'ä¸ªäºº':
                        if holding_ratio > 10 or holder_name in historical_insiders or holder_name in insider_names:
                            if holding_ratio < 5:
                                small_non_ratio += holding_ratio
                            else:
                                insider_ratio += holding_ratio
                        else:
                            retail_ratio += holding_ratio
                    elif holder_type == 'æŠ•èµ„å…¬å¸':
                        if holding_ratio > 20.0 or any(keyword in holder_name for keyword in ['å›½æœ‰', 'å›½èµ„']) or (stock_name[:2] in holder_name) or (stock_name in holder_name):
                            enterprise_ratio += holding_ratio
                        else:
                            category_ratios['æŠ•èµ„å…¬å¸'] += holding_ratio
                    elif holder_type == 'å…¶å®ƒ':
                        if 'é¦™æ¸¯ä¸­å¤®ç»“ç®—' in holder_name:
                            hk_ratio += holding_ratio
                        elif holding_ratio > 20.0:
                            enterprise_ratio += holding_ratio
                        elif any(keyword in holder_name for keyword in ['å…¬å¸', 'å›½æœ‰']) or (stock_name[:2] in holder_name) or (stock_name in holder_name):
                            if holding_ratio < 5:
                                small_non_enterprise_ratio += holding_ratio
                            else:
                                enterprise_ratio += holding_ratio
                        else:
                            category_ratios['å…¶å®ƒ'] += holding_ratio
                    elif holder_type in categories:
                        category_ratios[holder_type] += holding_ratio
                    
                    # ä»£ç 2æ–°å¢é€»è¾‘
                    top10_total_ratio += holding_ratio
                    
                    if holding_ratio < 5.0:
                        top10_small_non_ratio += holding_ratio
                    else:
                        top10_large_non_ratio += holding_ratio
                    
                    is_individual = "ä¸ªäºº" in str(holder_type) or "è‡ªç„¶äºº" in str(holder_name)
                    is_hk_central = "é¦™æ¸¯ä¸­å¤®ç»“ç®—" in str(holder_name)
                    
                    if not is_individual and not is_hk_central:
                        if holding_ratio >= 5.0:
                            institutional_large_non_ratio += holding_ratio
                        else:
                            institutional_small_non_ratio += holding_ratio
                
                print(f"âœ… åå¤§æµé€šè‚¡ä¸œæ•°æ®å¤„ç†å®Œæˆ: {stock_name}")
                print(f"âœ… æ–°å¢æŒ‡æ ‡ - å‰10å¤§æµé€šè‚¡ä¸œæŒè‚¡æ¯”ä¾‹åˆè®¡: {top10_total_ratio:.1f}%")
                print(f"âœ… æ–°å¢æŒ‡æ ‡ - åå¤§æµé€šè‚¡ä¸œå°éåˆè®¡: {top10_small_non_ratio:.1f}%")
                print(f"âœ… æ–°å¢æŒ‡æ ‡ - åå¤§æµé€šè‚¡ä¸œå¤§éåˆè®¡: {top10_large_non_ratio:.1f}%")
                print(f"âœ… æ–°å¢æŒ‡æ ‡ - åå¤§æµé€šæœºæ„å¤§é: {institutional_large_non_ratio:.1f}%")
                print(f"âœ… æ–°å¢æŒ‡æ ‡ - åå¤§æµé€šæœºæ„å°é: {institutional_small_non_ratio:.1f}%")
        except Exception as e:
            print(f"âŒâŒâŒâŒ åå¤§æµé€šè‚¡ä¸œæ•°æ®å¤„ç†å¤±è´¥ (è‚¡ç¥¨: {stock_name}): {str(e)}")
    else:
        print("âš ï¸ å·²å…³é—­åå¤§æµé€šè‚¡ä¸œæŸ¥è¯¢")

    # ç»“æœæ ¼å¼åŒ–
    result_data = {
        'è‚¡ç¥¨åç§°': stock_name,
        'æ•°æ®æ—¥æœŸ': current_target_date,
        'ä¿¡å·å½“æ—¥æµé€šå¸‚å€¼(å…ƒ)': f'{circulating_mv:,.0f}',
        'ä¿¡å·å½“æ—¥ä»·æ ¼': f'{signal_price:.2f}' if signal_price is not None else 'N/A',
        'ä¿¡å·å½“æ—¥æ—¥æœŸ': signal_price_date or price_date,
        'åŸå§‹ä¿¡å·æ—¥æœŸ': entry.get("signal_date"),
        'é«˜ç®¡/å¤§è‚¡ä¸œæŒè‚¡æ¯”ä¾‹': f'{insider_ratio:.1f}%',
        'é«˜ç®¡/å¤§è‚¡ä¸œæŒè‚¡æ¯”ä¾‹ï¼ˆå°éï¼‰': f'{small_non_ratio:.1f}%',
        'æ™®é€šæ•£æˆ·æŒè‚¡æ¯”ä¾‹': f'{retail_ratio:.1f}%',
        'é¦™æ¸¯ä¸­å¤®ç»“ç®—': f'{hk_ratio:.1f}%',
        'ä¼ä¸šå¤§è‚¡ä¸œï¼ˆåŒ…å«å›½èµ„ï¼‰': f'{enterprise_ratio:.1f}%',
        'ä¼ä¸šå¤§è‚¡ä¸œï¼ˆåŒ…å«å›½èµ„ï¼‰ï¼ˆå°éï¼‰': f'{small_non_enterprise_ratio:.1f}%',
        **{k: f'{v:.1f}%' for k, v in category_ratios.items()},
        # ä»£ç 2æ–°å¢å­—æ®µ
        'å‰10å¤§æµé€šè‚¡ä¸œæŒè‚¡æ¯”ä¾‹åˆè®¡': f'{top10_total_ratio:.1f}%',
        'åå¤§æµé€šè‚¡ä¸œå°éåˆè®¡': f'{top10_small_non_ratio:.1f}%',
        'åå¤§æµé€šè‚¡ä¸œå¤§éåˆè®¡': f'{top10_large_non_ratio:.1f}%',
        'åå¤§æµé€šæœºæ„å¤§é': f'{institutional_large_non_ratio:.1f}%',
        'åå¤§æµé€šæœºæ„å°é': f'{institutional_small_non_ratio:.1f}%'
    }
    
    # æŸ¥è¯¢æŒä»“æ•°æ®
    if FEATURE_FLAGS["è·å–æœºæ„æŒä»“"]:
        print("  æ­£åœ¨æŸ¥è¯¢æŒä»“æ•°æ®...")
        for hold_type in hold_types:
            result_data[hold_type + "å æ¯”"] = "N/A"
        result_data["æŒæœ‰åŸºé‡‘å®¶æ•°"] = 0

        for hold_type in hold_types:
            stock_row = (
                fund_hold_map.get(current_target_date, {})
                .get(hold_type, {})
                .get(stock_code_pure)
            )
            if stock_row is None or (isinstance(stock_row, pd.Series) and stock_row.empty):
                result_data[hold_type + "å æ¯”"] = "0.0%"
                continue

            market_value = stock_row.get("æŒè‚¡å¸‚å€¼", 0)
            if market_value and circulating_mv > 0:
                hold_ratio = (market_value / circulating_mv) * 100
                result_data[hold_type + "å æ¯”"] = f"{hold_ratio:.1f}%"
                print(f"    âœ… {hold_type}å æ¯”: {hold_ratio:.1f}%")
            else:
                result_data[hold_type + "å æ¯”"] = "N/A"
                print(f"    âš âš âš âš âš ï¸ æ— æ³•è®¡ç®—{hold_type}å æ¯” (è‚¡ç¥¨: {stock_name})")

            if hold_type == "åŸºé‡‘æŒä»“":
                fund_hold_count = stock_row.get("æŒæœ‰åŸºé‡‘å®¶æ•°", 0)
                result_data["æŒæœ‰åŸºé‡‘å®¶æ•°"] = int(fund_hold_count) if pd.notna(fund_hold_count) else 0
    else:
        print("âš ï¸ å·²å…³é—­æŒä»“æ•°æ®æŸ¥è¯¢")
        for hold_type in hold_types:
            result_data[hold_type + "å æ¯”"] = "N/A"
        result_data["æŒæœ‰åŸºé‡‘å®¶æ•°"] = 0
    
    result_list.append(result_data)
    cache[cache_key] = result_data.copy()
    print(f"âœ… è‚¡ç¥¨å¤„ç†å®Œæˆ: {stock_name}")
    
    # æ¯å¤„ç†10ä¸ªè‚¡ç¥¨è‡ªåŠ¨ä¿å­˜ä¸€æ¬¡ï¼ˆé™ä½é¢‘ç‡ä»¥å‡å°‘ä¸­æ–­æŸå¤±ï¼‰
    if idx % 10 == 0:
        print(f"\nğŸ’¾ğŸ’¾ğŸ’¾ğŸ’¾ å·²å¤„ç† {idx} åªè‚¡ç¥¨ï¼Œæ­£åœ¨ä¿å­˜ä¸­é—´ç»“æœ...")
        try:
            # è¯»å–ç°æœ‰ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            if os.path.exists(save_path):
                existing_df = pd.read_excel(save_path)
                new_df = pd.concat([existing_df, pd.DataFrame(result_list)], ignore_index=True)
            else:
                new_df = pd.DataFrame(result_list)
                
            new_df.to_excel(save_path, index=False)
            print(f"âœ… ä¸­é—´ç»“æœå·²ä¿å­˜è‡³: {save_path}")
            result_list = []  # æ¸…ç©ºç»“æœåˆ—è¡¨
            print(f"ğŸ“ˆ å½“å‰è¯·æ±‚ç»Ÿè®¡: {client.metrics()}")
        except Exception as e:
            print(f"âŒâŒâŒâŒ ä¿å­˜ä¸­é—´ç»“æœå¤±è´¥: {str(e)}")

# ä¿å­˜æœ€ç»ˆç»“æœ
print("\nğŸ’¾ğŸ’¾ğŸ’¾ğŸ’¾ æ­£åœ¨ä¿å­˜æœ€ç»ˆç»“æœ...")
try:
    # è¯»å–ç°æœ‰ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
    if os.path.exists(save_path) and len(result_list) > 0:
        existing_df = pd.read_excel(save_path)
        final_df = pd.concat([existing_df, pd.DataFrame(result_list)], ignore_index=True)
    elif len(result_list) > 0:
        final_df = pd.DataFrame(result_list)
    else:
        print("âš ï¸ æ²¡æœ‰æ–°æ•°æ®éœ€è¦ä¿å­˜")
        sys.exit(0)
        
    final_df.to_excel(save_path, index=False)
    print(f"âœ… æœ€ç»ˆç»“æœå·²ä¿å­˜è‡³: {save_path}")
    print(f"ğŸ“ˆ æœ€ç»ˆè¯·æ±‚ç»Ÿè®¡: {client.metrics()}")
except Exception as e:
    print(f"âŒâŒâŒâŒ ä¿å­˜æœ€ç»ˆç»“æœå¤±è´¥: {str(e)}")
    sys.exit(1)

# è¾“å‡ºæ‰§è¡Œæ—¶é—´
end_time = datetime.now()
total_time = (end_time - start_time).seconds
minutes, seconds = divmod(total_time, 60)
print(f"â±â±â±â±â±â±â±â±â±ï¸ ç»“æŸæ‰§è¡Œæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
print(f"â±â±â±â±â±â±â±â±â±ï¸ æ€»è€—æ—¶: {minutes}åˆ†{seconds}ç§’")
print(f"ğŸ“ŠğŸ“ŠğŸ“ŠğŸ“Š æˆåŠŸå¤„ç† {len(stocks_to_process)} æ¡è®°å½•")
