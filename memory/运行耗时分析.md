# 因子分析运行耗时评估与优化方案（Codex）

## 背景
- 12 月 5 日最新三次完整运行的总耗时分别为 783.66s、976.09s、870.75s（`baogao/factor_analysis_log_20251205_114118.txt:1`、`baogao/factor_analysis_log_20251205_183443.txt:1`、`baogao/factor_analysis_log_20251205_191507.txt:1`），明显超出预期，需要定位瓶颈并提出可执行的改善方案。
- 分析对象为非参数主流程，对应 20 个因子、1148 个信号分组，涵盖 5 年 21k 行数据。

## 当前耗时概况

| 日志文件 | 总耗时 (s) | 中性化阶段 (s×2) | 核心计算 (s) | 辅助统计合并 (s) |
| --- | --- | --- | --- | --- |
| factor_analysis_log_20251205_114118.txt | 783.66 | 173.65 / 168.80 | 237.10 | 349.03 |
| factor_analysis_log_20251205_183443.txt | 976.09 | 227.37 / 213.05 | 351.68 | 369.36 |
| factor_analysis_log_20251205_191507.txt | 870.75 | 191.69 / 186.08 | 316.26 | 334.78 |

> 注：中性化阶段会在“预处理”和“因子分析”各执行一次，因此日志中出现两条 `neutralized … in …s`。

## 主要瓶颈分析

1. **双次中性化耗时 180–230s**  
   - `FactorNeutralizer` 每次都要按 1148 个信号分组回归，19 个因子共运行两轮（预处理、分析）。  
   - 行业哑变量在每个信号日都会重新构造，且市值对数序列也重复构建，缺少缓存。  
   - 单因子模式为顺序执行，没有利用多核资源。

2. **核心非参数计算 237–352s**  
   - `calculate_ic` 会针对每个因子再遍历所有信号日滑窗，启用 Kendall、robust corr、Bootstrap 等所有附加统计，导致单因子耗时较长。  
   - `calculate_group_returns` 对 10 等分排序后进行多次聚合，且结果未缓存；正/负因子分析与报告阶段又多次访问相同数据。  
   - `_fa_classify_factors_by_ic`、评分、报告等后续流程仍然逐因子重复计算多项指标，缺乏复用。

3. **辅助统计与报告合并 335–369s**  
   - `Auxiliary robustness statistics merged successfully in …` 时间与核心阶段相当，说明滚动 IC、样本敏感性等扩展计算量巨大。  
   - 报告生成过程会将大量 DataFrame 复制、格式化（尤其是 `fa_nonparam_report` 中多次调用 `render_table` 与 `render_metric_cards`），在 20 个因子时已接近 5 分钟。

4. **启动/收尾开销**  
   - 每轮都会重新加载并校验 5 份 Excel 表，验证信息较多但必要性较低；日志输出极其冗长，也会拖慢终端 IO。

## 优化方案

1. **合并/缓存中性化结果**  
   - 仅在预处理阶段运行 `FactorNeutralizer`，将中性化后的列命名为 `<factor>__neutral` 并在 `calculate_ic` 等处复用；因子分析阶段读取缓存列即可，避免重复回归。  
   - `FactorNeutralizer` 内部缓存 `self._group_indices`、`log_cap_series`、行业哑变量，放在 init 后共享，必要时开启 `joblib` 或 `multiprocessing` 将因子批量处理（例如 4 线程并行，预计可将 190s 降到 60–80s）。  
   - 若某些因子只需行业或市值中性，则在配置层跳过多余的回归，以减少矩阵运算时间。

2. **裁剪 IC 计算附加项**  
   - 默认关闭 Kendall、robust corr、Bootstrap，仅在用户显式启用“深度诊断”时运行；日常批量分析仅保留 Spearman + t/p 即可，使 `calculate_ic` 单因子耗时下降 30–40%。  
   - 将 `calculate_ic` 产生的 `daily_ics`、`group_results` 缓存在 `analysis_results`，供后续报告直接使用，避免重复分组/排序。  
   - 对 `calculate_group_returns` 增加“快照缓存”或调用级别的 memoization，确保正/负因子分析不再重复计算。

3. **加速辅助统计**  
   - `rolling_window_analysis`、`temporal_stability_analysis`、`sample_sensitivity_analysis` 的窗口和抽样次数可按场景降级（例如默认只跑 30 日窗口 + 80% 抽样 20 次），在需要精细报告时再切换“大型配置”。  
   - 在生成报告前先将所有必须的 DataFrame 合并成单个对象，减少多次 `render_table` 的复制开销；可考虑分阶段输出（例如只在“精简版”保留 TOP 5 详情，其余指标写入 CSV）。

4. **减少重复 IO 与日志**  
   - 将多表加载的验证结果持久化，若数据文件未变化（可比较 mtime 或 hash），则跳过 `DataValidator` 的深度检查。  
   - 降低日志粒度，仅在 `--debug` 时打印每个因子的详细信息；普通模式只输出阶段性耗时，减少终端输出带来的阻塞。

5. **监控与后续扩展**  
   - 在 `log_metrics.csv` 中追加每阶段耗时、配置、机器信息，方便观察优化效果。  
   - 预留“分批因子分析”功能：允许只选择部分因子运行，以便开发/调试时缩短反馈周期。

## 行动建议
1. **短期（<1 天）**：  
   - 合并中性化执行 + 关闭默认的 Kendall/Bootstrap；  
   - 缓存 `calculate_group_returns` / `daily_ics` 并复用；  
   - 限制日志为阶段摘要。

2. **中期（1–3 天）**：  
   - 引入分阶段配置（标准模式 vs 深度诊断）；  
   - 实作多线程/分批中性化；  
   - 优化报告渲染（减少冗余表格、仅生成需要的 HTML）。

3. **长期（>3 天）**：  
   - 将因子分析核心逻辑抽象成管线，支持增量更新（仅对新增信号日期运行）；  
   - 探索 Cython/Numba/GPU 等方式进一步加速分组统计。  
   - 在调度层面监控 CPU/内存占用，必要时拆分至多台机器并行。

---
通过上述改造，关键阶段（中性化 + 核心计算 + 辅助统计）预计可将单次运行耗时从 14–16 分钟降至 6–8 分钟，同时保留“深度模式”以满足需要高质量诊断的场景。下一步建议先验证“单次中性化 + 精简 IC 附加项”的收益，再逐步上线其它优化。***
